{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-19T22:13:36.449677Z",
     "start_time": "2025-06-19T22:13:35.300939Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import os\n",
    "\n",
    "def process_empty_qualitative_factors(\n",
    "    csv_path: str,\n",
    "    output_path: str = None,\n",
    "    replace_with_nan: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    정성적 요인 컬럼에서 빈 배열을 NaN 또는 None으로 처리\n",
    "\n",
    "    Args:\n",
    "        csv_path: 입력 CSV 파일 경로\n",
    "        output_path: 출력 CSV 파일 경로 (None이면 원본 파일명에 _processed 추가)\n",
    "        replace_with_nan: True면 NaN, False면 None으로 처리\n",
    "\n",
    "    Returns:\n",
    "        처리된 DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # CSV 파일 로드\n",
    "    print(\"CSV 파일 로딩 중...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # 출력 경로 설정\n",
    "    if output_path is None:\n",
    "        base_path = os.path.splitext(csv_path)[0]\n",
    "        output_path = f\"{base_path}_processed.csv\"\n",
    "\n",
    "    # 빈 배열 개수 카운트 (처리 전)\n",
    "    positive_empty_count = 0\n",
    "    negative_empty_count = 0\n",
    "\n",
    "    print(\"빈 배열 검사 및 처리 중...\")\n",
    "\n",
    "    # positive_factors 처리\n",
    "    for idx, value in df['positive_factors'].items():\n",
    "        if pd.isna(value) or value == '' or value == '[]':\n",
    "            positive_empty_count += 1\n",
    "            df.at[idx, 'positive_factors'] = np.nan if replace_with_nan else None\n",
    "        else:\n",
    "            try:\n",
    "                # JSON 문자열을 파싱하여 빈 배열인지 확인\n",
    "                parsed = json.loads(value) if isinstance(value, str) else value\n",
    "                if isinstance(parsed, list) and len(parsed) == 0:\n",
    "                    positive_empty_count += 1\n",
    "                    df.at[idx, 'positive_factors'] = np.nan if replace_with_nan else None\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # JSON 파싱 실패시 원본 유지\n",
    "                pass\n",
    "\n",
    "    # negative_factors 처리\n",
    "    for idx, value in df['negative_factors'].items():\n",
    "        if pd.isna(value) or value == '' or value == '[]':\n",
    "            negative_empty_count += 1\n",
    "            df.at[idx, 'negative_factors'] = np.nan if replace_with_nan else None\n",
    "        else:\n",
    "            try:\n",
    "                # JSON 문자열을 파싱하여 빈 배열인지 확인\n",
    "                parsed = json.loads(value) if isinstance(value, str) else value\n",
    "                if isinstance(parsed, list) and len(parsed) == 0:\n",
    "                    negative_empty_count += 1\n",
    "                    df.at[idx, 'negative_factors'] = np.nan if replace_with_nan else None\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # JSON 파싱 실패시 원본 유지\n",
    "                pass\n",
    "\n",
    "    # 결과 저장\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "    # 처리 결과 출력\n",
    "    print(f\"\\n=== 처리 결과 ===\")\n",
    "    print(f\"총 행 수: {len(df):,}\")\n",
    "    print(f\"빈 positive_factors 처리: {positive_empty_count:,}개\")\n",
    "    print(f\"빈 negative_factors 처리: {negative_empty_count:,}개\")\n",
    "    print(f\"처리 후 positive_factors NaN 비율: {df['positive_factors'].isna().sum() / len(df) * 100:.1f}%\")\n",
    "    print(f\"처리 후 negative_factors NaN 비율: {df['negative_factors'].isna().sum() / len(df) * 100:.1f}%\")\n",
    "    print(f\"처리된 파일 저장: {output_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def analyze_qualitative_data_quality(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    정성적 데이터의 품질을 분석\n",
    "\n",
    "    Args:\n",
    "        df: 분석할 DataFrame\n",
    "\n",
    "    Returns:\n",
    "        분석 결과 딕셔너리\n",
    "    \"\"\"\n",
    "\n",
    "    analysis = {\n",
    "        'total_records': len(df),\n",
    "        'positive_factors': {},\n",
    "        'negative_factors': {}\n",
    "    }\n",
    "\n",
    "    for col_name in ['positive_factors', 'negative_factors']:\n",
    "        col = df[col_name]\n",
    "\n",
    "        # 기본 통계\n",
    "        null_count = col.isna().sum()\n",
    "        valid_count = len(df) - null_count\n",
    "\n",
    "        # 유효한 데이터에서 요인 개수 분석\n",
    "        factor_counts = []\n",
    "        for value in col.dropna():\n",
    "            if isinstance(value, str) and value.strip():\n",
    "                try:\n",
    "                    parsed = json.loads(value)\n",
    "                    if isinstance(parsed, list):\n",
    "                        factor_counts.append(len(parsed))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        analysis[col_name] = {\n",
    "            'null_count': int(null_count),\n",
    "            'valid_count': int(valid_count),\n",
    "            'null_percentage': round(null_count / len(df) * 100, 2),\n",
    "            'valid_percentage': round(valid_count / len(df) * 100, 2),\n",
    "            'avg_factors_per_record': round(np.mean(factor_counts), 2) if factor_counts else 0,\n",
    "            'max_factors_per_record': max(factor_counts) if factor_counts else 0,\n",
    "            'min_factors_per_record': min(factor_counts) if factor_counts else 0\n",
    "        }\n",
    "\n",
    "    return analysis\n",
    "\n",
    "def sample_qualitative_data(df: pd.DataFrame, n_samples: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    정성적 데이터 샘플을 추출하여 품질 확인\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        n_samples: 샘플 개수\n",
    "\n",
    "    Returns:\n",
    "        샘플 DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # 유효한 정성적 데이터가 있는 행들만 필터링\n",
    "    valid_rows = df[\n",
    "        (df['positive_factors'].notna()) &\n",
    "        (df['negative_factors'].notna()) &\n",
    "        (df['positive_factors'] != '[]') &\n",
    "        (df['negative_factors'] != '[]')\n",
    "    ]\n",
    "\n",
    "    if len(valid_rows) == 0:\n",
    "        print(\"유효한 정성적 데이터가 있는 행이 없습니다.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 랜덤 샘플링\n",
    "    sample_df = valid_rows.sample(min(n_samples, len(valid_rows)))\n",
    "\n",
    "    # 관련 컬럼만 선택\n",
    "    columns_to_show = ['corp_code', 'corp_name', 'positive_factors', 'negative_factors']\n",
    "    available_columns = [col for col in columns_to_show if col in sample_df.columns]\n",
    "\n",
    "    return sample_df[available_columns]\n",
    "\n",
    "# 실행 함수\n",
    "def main():\n",
    "    \"\"\"\n",
    "    메인 실행 함수\n",
    "    \"\"\"\n",
    "\n",
    "    # 파일 경로 설정\n",
    "    input_file = \"D:/JetBrains/ai/add-data-real-company/integrated_financial_qualitative_data.csv\"\n",
    "    output_file = \"D:/JetBrains/ai/add-data-real-company/integrated_financial_qualitative_data_processed.csv\"\n",
    "\n",
    "    try:\n",
    "        # 1. 빈 배열을 NaN으로 처리\n",
    "        print(\"=== 빈 배열 처리 시작 ===\")\n",
    "        df_processed = process_empty_qualitative_factors(input_file, output_file)\n",
    "\n",
    "        # 2. 데이터 품질 분석\n",
    "        print(\"\\n=== 데이터 품질 분석 ===\")\n",
    "        quality_analysis = analyze_qualitative_data_quality(df_processed)\n",
    "\n",
    "        print(f\"총 레코드 수: {quality_analysis['total_records']:,}\")\n",
    "        print(\"\\n[Positive Factors 분석]\")\n",
    "        pos_stats = quality_analysis['positive_factors']\n",
    "        print(f\"  - 유효 데이터: {pos_stats['valid_count']:,}개 ({pos_stats['valid_percentage']}%)\")\n",
    "        print(f\"  - NaN 데이터: {pos_stats['null_count']:,}개 ({pos_stats['null_percentage']}%)\")\n",
    "        print(f\"  - 평균 요인 수: {pos_stats['avg_factors_per_record']}개\")\n",
    "\n",
    "        print(\"\\n[Negative Factors 분석]\")\n",
    "        neg_stats = quality_analysis['negative_factors']\n",
    "        print(f\"  - 유효 데이터: {neg_stats['valid_count']:,}개 ({neg_stats['valid_percentage']}%)\")\n",
    "        print(f\"  - NaN 데이터: {neg_stats['null_count']:,}개 ({neg_stats['null_percentage']}%)\")\n",
    "        print(f\"  - 평균 요인 수: {neg_stats['avg_factors_per_record']}개\")\n",
    "\n",
    "        # 3. 샘플 데이터 확인\n",
    "        print(\"\\n=== 샘플 데이터 (정성적 요인이 있는 기업들) ===\")\n",
    "        sample_data = sample_qualitative_data(df_processed, 5)\n",
    "\n",
    "        if not sample_data.empty:\n",
    "            for idx, row in sample_data.iterrows():\n",
    "                print(f\"\\n기업코드: {row.get('corp_code', 'N/A')}\")\n",
    "                if 'corp_name' in row:\n",
    "                    print(f\"기업명: {row['corp_name']}\")\n",
    "\n",
    "                # positive_factors 출력\n",
    "                try:\n",
    "                    pos_factors = json.loads(row['positive_factors']) if isinstance(row['positive_factors'], str) else []\n",
    "                    print(f\"긍정 요인 ({len(pos_factors)}개): {pos_factors}\")\n",
    "                except:\n",
    "                    print(f\"긍정 요인: {row['positive_factors']}\")\n",
    "\n",
    "                # negative_factors 출력\n",
    "                try:\n",
    "                    neg_factors = json.loads(row['negative_factors']) if isinstance(row['negative_factors'], str) else []\n",
    "                    print(f\"부정 요인 ({len(neg_factors)}개): {neg_factors}\")\n",
    "                except:\n",
    "                    print(f\"부정 요인: {row['negative_factors']}\")\n",
    "\n",
    "        print(f\"\\n✅ 처리 완료! 결과 파일: {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 빈 배열 처리 시작 ===\n",
      "CSV 파일 로딩 중...\n",
      "빈 배열 검사 및 처리 중...\n",
      "\n",
      "=== 처리 결과 ===\n",
      "총 행 수: 2,059\n",
      "빈 positive_factors 처리: 1,072개\n",
      "빈 negative_factors 처리: 245개\n",
      "처리 후 positive_factors NaN 비율: 52.1%\n",
      "처리 후 negative_factors NaN 비율: 11.9%\n",
      "처리된 파일 저장: D:/JetBrains/ai/add-data-real-company/integrated_financial_qualitative_data_processed.csv\n",
      "\n",
      "=== 데이터 품질 분석 ===\n",
      "총 레코드 수: 2,059\n",
      "\n",
      "[Positive Factors 분석]\n",
      "  - 유효 데이터: 987개 (47.94%)\n",
      "  - NaN 데이터: 1,072개 (52.06%)\n",
      "  - 평균 요인 수: 2.48개\n",
      "\n",
      "[Negative Factors 분석]\n",
      "  - 유효 데이터: 1,814개 (88.1%)\n",
      "  - NaN 데이터: 245개 (11.9%)\n",
      "  - 평균 요인 수: 2.38개\n",
      "\n",
      "=== 샘플 데이터 (정성적 요인이 있는 기업들) ===\n",
      "\n",
      "기업코드: 204320.0\n",
      "기업명: HL만도\n",
      "긍정 요인 (2개): ['HL만도는 2014년 HL 홀딩스로부터 인적 분할된 이후 안정적인 재무제표를 유지하고 있으며, 삼일회계법인에서 감사받은 신뢰성 있는 재무정보를 보유하고 있다.', '자동차 부품 시장에서의 위치를 고려할 때, 지속적인 기술력 강화와 파트너십 확대 가능성이 존재한다.']\n",
      "부정 요인 (2개): ['자산총액이 2조원 미만으로, 연결재무제표 의무 공시가 유예되어 있어 재무상태에 대한 불확실성이 존재한다.', '현금 창출 단위의 손상 가능성이 언급되어 있어, 향후 재무적 위험이 우려된다.']\n",
      "\n",
      "기업코드: 1040.0\n",
      "기업명: CJ\n",
      "긍정 요인 (3개): ['CJ 그룹은 다양한 사업 부문을 운영하며, 특히 식품 및 엔터테인먼트 분야에서 강력한 시장 지위를 보유하고 있음.', 'CJ대한통운은 물류 및 신유통 분야에서의 성장 가능성을 가지고 있으며, 이는 전체 그룹의 매출 증대에 기여할 것으로 예상됨.', 'CJ제일제당의 생명공학 및 바이오 사업 부문은 기술력 강화와 함께 시장 점유율 확대가 기대됨.']\n",
      "부정 요인 (2개): ['경쟁 심화로 인해 식품 및 엔터테인먼트 분야에서의 시장 점유율 하락 위험이 존재함.', '부채 증가와 관련된 재무적 부담이 우려되며, 이는 유동성 문제로 이어질 수 있음.']\n",
      "\n",
      "기업코드: 28300.0\n",
      "기업명: HLB\n",
      "긍정 요인 (3개): ['HLB는 의료용품 및 기타 의약 관련 제품 제조업에 종사하며, 이는 안정적인 시장 수요를 반영할 수 있음.', '신재생에너지 사업 진출로 새로운 성장 동력을 확보할 가능성이 있음.', 'HLB생명과학은 신약 개발에 집중하고 있어 기술력 강화와 시장 점유율 확대의 기회가 존재함.']\n",
      "부정 요인 (3개): ['의료기기 및 의약품 시장의 경쟁이 심화되고 있어 시장 점유율 하락 위험이 있음.', '부채 증가 및 유동성 부족에 대한 우려가 존재할 수 있음.', '규제 리스크가 존재하여 사업 환경에 부정적인 영향을 미칠 수 있음.']\n",
      "\n",
      "기업코드: 118000.0\n",
      "기업명: 메타케어\n",
      "긍정 요인 (2개): ['업종 PER이 24.70으로 업계 평균에 비해 경쟁력이 있는 수익성을 나타냄', '당기순이익이 최근 결산 기준으로 긍정적인 성장세를 보이고 있음']\n",
      "부정 요인 (1개): ['부채에 대한 정보가 부족하여 재무 안정성에 대한 우려가 존재함']\n",
      "\n",
      "기업코드: 85810.0\n",
      "기업명: 알티캐스트\n",
      "긍정 요인 (2개): ['1999년에 설립되어 2013년 코스닥 시장에 상장된 안정적인 기업 구조', '디지털 방송용 소프트웨어 솔루션 개발 및 공급업으로 특화된 기술력 보유']\n",
      "부정 요인 (2개): ['최근 주가가 하락세를 보이며 시장에서의 신뢰도 감소', '재무제표에서 ROA와 ROE 정보가 누락되어 재무 건전성에 대한 불확실성 존재']\n",
      "\n",
      "✅ 처리 완료! 결과 파일: D:/JetBrains/ai/add-data-real-company/integrated_financial_qualitative_data_processed.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4332c630c22b79e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
