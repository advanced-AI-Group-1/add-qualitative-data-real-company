{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging"
   ],
   "id": "40b44c85c6538fbf",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "ddcf0c18bfd37eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:29:01,003 - INFO - Loading search results...\n",
      "2025-06-20 00:29:01,060 - INFO - Loaded 500 records from D:/JetBrains/ai/add-data-real-company\\search_results_1.json\n",
      "2025-06-20 00:29:01,062 - INFO - Sample data structure for 33790.0:\n",
      "2025-06-20 00:29:01,063 - INFO - Keys: ['query', 'corp_code', 'timestamp', 'results']\n",
      "2025-06-20 00:29:01,064 - INFO - Results type: <class 'dict'>\n",
      "2025-06-20 00:29:01,064 - INFO - Results dict keys: ['query', 'follow_up_questions', 'answer', 'images', 'results', 'response_time']\n",
      "2025-06-20 00:29:01,103 - INFO - Loaded 500 records from D:/JetBrains/ai/add-data-real-company\\search_results_2.json\n",
      "2025-06-20 00:29:01,145 - INFO - Loaded 500 records from D:/JetBrains/ai/add-data-real-company\\search_results_3.json\n",
      "2025-06-20 00:29:01,182 - INFO - Loaded 500 records from D:/JetBrains/ai/add-data-real-company\\search_results_4.json\n",
      "2025-06-20 00:29:01,188 - INFO - Loaded 59 records from D:/JetBrains/ai/add-data-real-company\\search_results_5.json\n",
      "2025-06-20 00:29:01,190 - INFO - Total loaded records: 2059\n",
      "2025-06-20 00:29:01,192 - INFO - Preparing batch requests...\n",
      "2025-06-20 00:29:01,200 - WARNING - Unexpected results structure for corp_code 17680.0: <class 'str'>\n",
      "2025-06-20 00:29:01,313 - INFO - Created batch file: qualitative_analysis_batch.jsonl with 2059 requests\n",
      "2025-06-20 00:29:01,315 - INFO - Submitting batch to OpenAI...\n",
      "2025-06-20 00:29:03,567 - INFO - HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "2025-06-20 00:29:03,998 - INFO - HTTP Request: POST https://api.openai.com/v1/batches \"HTTP/1.1 200 OK\"\n",
      "2025-06-20 00:29:04,000 - INFO - Batch submitted with ID: batch_68542cbf980c819080143b8a1a906b4a\n",
      "2025-06-20 00:29:04,001 - INFO - Waiting for batch completion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: batch_68542cbf980c819080143b8a1a906b4a\n",
      "배치 작업이 제출되었습니다. 완료까지 시간이 걸릴 수 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:29:04,251 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:30:04,543 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:31:04,879 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:32:05,248 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:33:05,559 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:34:05,876 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:35:06,247 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:36:06,781 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:37:07,063 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:38:07,348 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:39:07,660 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:40:07,990 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:41:08,299 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:42:08,604 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:43:08,887 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:44:09,194 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:45:09,473 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:46:09,772 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:47:10,080 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:48:10,393 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:49:10,662 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:50:10,972 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:51:11,259 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:52:11,556 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:53:11,997 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:54:12,317 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:55:12,669 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:56:12,949 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:57:13,322 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:58:13,660 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 00:59:13,951 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:00:14,286 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:01:14,597 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:02:14,920 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:03:15,254 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:04:15,554 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:05:15,852 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:06:16,141 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:07:16,459 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:08:16,764 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:09:17,064 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:10:17,421 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:11:17,686 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:12:18,023 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:13:18,340 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:14:18,640 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:15:18,943 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:16:19,278 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:17:19,612 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:18:19,908 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:19:20,216 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:20:20,515 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:21:20,844 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:22:21,162 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:23:21,464 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:24:21,751 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:25:22,088 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:26:22,380 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:27:22,656 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:28:22,983 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:29:23,286 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:30:23,900 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:31:24,428 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:32:24,728 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:33:25,287 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:34:25,560 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:35:25,874 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:36:26,210 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:37:26,504 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:38:26,822 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:39:27,159 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:40:27,445 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:41:27,744 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:42:28,014 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:43:28,285 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:44:28,576 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:45:28,895 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:46:29,182 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:47:29,462 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:48:30,130 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:49:30,417 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:50:30,707 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:51:31,015 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:52:31,300 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:53:31,568 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:54:31,848 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:55:32,145 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:56:32,447 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:57:32,716 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:58:33,049 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 01:59:33,363 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:00:33,688 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:01:33,986 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:02:34,244 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:03:34,613 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:04:35,017 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:05:35,310 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:06:35,627 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:07:35,903 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:08:36,214 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:09:36,520 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:10:36,855 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:11:37,206 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:12:37,699 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:13:37,964 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:14:38,282 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:15:38,595 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:16:38,933 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:17:39,238 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:18:39,536 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:19:39,795 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:20:40,079 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:21:40,401 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:22:40,666 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:23:40,964 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:24:41,217 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:25:41,528 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:26:41,780 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:27:42,057 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:28:42,342 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:29:42,612 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:30:42,897 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:31:43,181 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:32:43,458 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:33:43,740 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:34:44,046 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:35:44,324 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:36:44,623 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: in_progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:37:44,898 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: finalizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:38:45,212 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: finalizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:39:45,474 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: finalizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:40:45,726 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: finalizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:41:45,984 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n",
      "2025-06-20 02:41:45,987 - INFO - Batch completed successfully!\n",
      "2025-06-20 02:41:45,989 - INFO - Downloading batch results...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 02:41:46,210 - INFO - HTTP Request: GET https://api.openai.com/v1/batches/batch_68542cbf980c819080143b8a1a906b4a \"HTTP/1.1 200 OK\"\n",
      "2025-06-20 02:41:46,762 - INFO - HTTP Request: GET https://api.openai.com/v1/files/file-ALMuidjFsEYjM7KswSyjGa/content \"HTTP/1.1 200 OK\"\n",
      "2025-06-20 02:41:47,512 - INFO - Downloaded batch results to: qualitative_results.jsonl\n",
      "2025-06-20 02:41:47,513 - INFO - Parsing batch results...\n",
      "2025-06-20 02:41:47,573 - INFO - Integrating with financial data...\n",
      "2025-06-20 02:41:47,619 - INFO - Loaded financial data: 2059 records\n",
      "2025-06-20 02:41:47,862 - INFO - Matched 2058/2059 records with analysis results\n",
      "2025-06-20 02:41:47,966 - INFO - Integrated data saved to: D:/JetBrains/ai/add-data-real-company\\integrated_financial_qualitative_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! 통합된 데이터: 2059 행\n",
      "새로운 컬럼:\n",
      "- positive_factors: 긍정적 요인들\n",
      "- negative_factors: 부정적 요인들\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class QualitativeAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        정성적 분석을 위한 클래스 초기화\n",
    "\n",
    "        Args:\n",
    "            api_key: OpenAI API 키\n",
    "        \"\"\"\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        self.batch_requests = []\n",
    "\n",
    "    def load_search_results(self, folder_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        search_results_*.json 파일들을 모두 로드\n",
    "\n",
    "        Args:\n",
    "            folder_path: 검색 결과 JSON 파일들이 있는 폴더 경로\n",
    "\n",
    "        Returns:\n",
    "            모든 검색 결과를 통합한 딕셔너리\n",
    "        \"\"\"\n",
    "        all_results = {}\n",
    "\n",
    "        # search_results_*.json 파일들 찾기\n",
    "        for i in range(1, 10):  # 1~9까지 확인\n",
    "            file_path = os.path.join(folder_path, f\"search_results_{i}.json\")\n",
    "            if os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        all_results.update(data)\n",
    "                        logger.info(f\"Loaded {len(data)} records from {file_path}\")\n",
    "\n",
    "                        # 첫 번째 항목의 구조 확인 (디버깅용)\n",
    "                        if i == 1 and data:\n",
    "                            first_key = list(data.keys())[0]\n",
    "                            first_item = data[first_key]\n",
    "                            logger.info(f\"Sample data structure for {first_key}:\")\n",
    "                            logger.info(f\"Keys: {list(first_item.keys())}\")\n",
    "                            if 'results' in first_item:\n",
    "                                logger.info(f\"Results type: {type(first_item['results'])}\")\n",
    "                                if isinstance(first_item['results'], dict):\n",
    "                                    logger.info(f\"Results dict keys: {list(first_item['results'].keys())}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "        logger.info(f\"Total loaded records: {len(all_results)}\")\n",
    "        return all_results\n",
    "\n",
    "    def create_analysis_prompt(self, company_info: Dict) -> str:\n",
    "        \"\"\"\n",
    "        정성적 분석을 위한 프롬프트 생성\n",
    "\n",
    "        Args:\n",
    "            company_info: 기업 정보 딕셔너리\n",
    "\n",
    "        Returns:\n",
    "            분석 프롬프트 문자열\n",
    "        \"\"\"\n",
    "        corp_code = company_info.get('corp_code', 'Unknown')\n",
    "        corp_name = \"Unknown\"\n",
    "\n",
    "        # 쿼리에서 기업명 추출 시도\n",
    "        query = company_info.get('query', '')\n",
    "        if query:\n",
    "            corp_name = query.split()[0] if query.split() else \"Unknown\"\n",
    "\n",
    "        # JSON 구조에 맞게 검색 결과 접근: company_info['results']['results']\n",
    "        results_data = company_info.get('results', {})\n",
    "        if isinstance(results_data, dict):\n",
    "            search_results = results_data.get('results', [])\n",
    "        else:\n",
    "            search_results = []\n",
    "            logger.warning(f\"Unexpected results structure for corp_code {corp_code}: {type(results_data)}\")\n",
    "\n",
    "        # 검색 결과에서 내용 추출\n",
    "        content_summary = \"\"\n",
    "        if isinstance(search_results, list) and search_results:\n",
    "            for i, result in enumerate(search_results[:5]):  # 상위 5개 결과만 사용\n",
    "                if isinstance(result, dict):\n",
    "                    title = result.get('title', '')\n",
    "                    content = result.get('content', '')\n",
    "                    url = result.get('url', '')\n",
    "\n",
    "                    if title and content and content != \"Missing\":  # \"Missing\" 내용은 제외\n",
    "                        content_summary += f\"{i+1}. {title}\\n   내용: {content}\\n   출처: {url}\\n\\n\"\n",
    "\n",
    "        # 검색 결과가 없거나 유효하지 않은 경우 처리\n",
    "        if not content_summary.strip():\n",
    "            content_summary = f\"기업코드 {corp_code}({corp_name})에 대한 유효한 검색 결과가 부족합니다.\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "다음은 기업 코드 {corp_code}({corp_name})에 대한 검색 결과입니다. 이 정보를 바탕으로 신용등급 평가를 위한 정성적 요인들을 분석해주세요.\n",
    "\n",
    "검색 결과 내용:\n",
    "{content_summary}\n",
    "\n",
    "위 정보를 분석하여 다음 형태의 JSON으로 응답해주세요:\n",
    "\n",
    "{{\n",
    "    \"positive_factors\": [\n",
    "        \"구체적인 긍정적 요인 1\",\n",
    "        \"구체적인 긍정적 요인 2\"\n",
    "    ],\n",
    "    \"negative_factors\": [\n",
    "        \"구체적인 부정적 요인 1\",\n",
    "        \"구체적인 부정적 요인 2\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "분석 기준:\n",
    "1. 긍정적 요인:\n",
    "   - 매출 성장, 영업이익 개선, 시장 점유율 확대\n",
    "   - 신규 사업 진출, 기술력 강화, 파트너십 확대\n",
    "   - 재무구조 개선, 부채 감소, 유동성 증가\n",
    "   - 시장 지위 강화, 브랜드 가치 향상\n",
    "\n",
    "2. 부정적 요인:\n",
    "   - 매출 감소, 영업손실, 시장 점유율 하락\n",
    "   - 경쟁 심화, 규제 리스크, 사업 환경 악화\n",
    "   - 부채 증가, 유동성 부족, 재무 악화\n",
    "   - 경영진 교체, 법적 리스크, 평판 손상\n",
    "\n",
    "3. 주의사항:\n",
    "   - 각 요인은 검색 결과에 기반하여 구체적으로 작성\n",
    "   - 추측이나 일반론은 피하고 사실에 기반한 내용만 포함\n",
    "   - 정보가 부족하면 해당 배열을 비워두기\n",
    "   - 각 배열에 최대 3-5개 요인만 포함\n",
    "\n",
    "반드시 유효한 JSON 형태로만 응답하고 다른 설명은 포함하지 마세요.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def prepare_batch_requests(self, search_results: Dict, model: str = \"gpt-4o-mini\") -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Batch API 요청을 위한 요청 리스트 준비\n",
    "\n",
    "        Args:\n",
    "            search_results: 검색 결과 딕셔너리\n",
    "            model: 사용할 OpenAI 모델\n",
    "\n",
    "        Returns:\n",
    "            Batch API 요청 리스트\n",
    "        \"\"\"\n",
    "        batch_requests = []\n",
    "\n",
    "        for corp_code, company_info in search_results.items():\n",
    "            prompt = self.create_analysis_prompt(company_info)\n",
    "\n",
    "            request = {\n",
    "                \"custom_id\": f\"analysis_{corp_code}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"당신은 기업 신용분석 전문가입니다. 주어진 정보를 바탕으로 정확하고 객관적인 정성적 요인 분석을 수행합니다.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 1000,\n",
    "                    \"temperature\": 0.3\n",
    "                }\n",
    "            }\n",
    "            batch_requests.append(request)\n",
    "\n",
    "        return batch_requests\n",
    "\n",
    "    def create_batch_file(self, batch_requests: List[Dict], filename: str = \"batch_requests.jsonl\") -> str:\n",
    "        \"\"\"\n",
    "        Batch API용 JSONL 파일 생성\n",
    "\n",
    "        Args:\n",
    "            batch_requests: 배치 요청 리스트\n",
    "            filename: 저장할 파일명\n",
    "\n",
    "        Returns:\n",
    "            생성된 파일의 경로\n",
    "        \"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for request in batch_requests:\n",
    "                f.write(json.dumps(request, ensure_ascii=False) + '\\n')\n",
    "\n",
    "        logger.info(f\"Created batch file: {filename} with {len(batch_requests)} requests\")\n",
    "        return filename\n",
    "\n",
    "    def submit_batch(self, batch_file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        OpenAI Batch API에 작업 제출\n",
    "\n",
    "        Args:\n",
    "            batch_file_path: 배치 파일 경로\n",
    "\n",
    "        Returns:\n",
    "            배치 작업 ID\n",
    "        \"\"\"\n",
    "        # 파일 업로드\n",
    "        with open(batch_file_path, 'rb') as f:\n",
    "            batch_input_file = self.client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "\n",
    "        # 배치 작업 생성\n",
    "        batch = self.client.batches.create(\n",
    "            input_file_id=batch_input_file.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "                \"description\": \"Qualitative analysis for credit rating\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Batch submitted with ID: {batch.id}\")\n",
    "        return batch.id\n",
    "\n",
    "    def check_batch_status(self, batch_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        배치 작업 상태 확인\n",
    "\n",
    "        Args:\n",
    "            batch_id: 배치 작업 ID\n",
    "\n",
    "        Returns:\n",
    "            배치 상태 정보\n",
    "        \"\"\"\n",
    "        batch = self.client.batches.retrieve(batch_id)\n",
    "        return {\n",
    "            \"id\": batch.id,\n",
    "            \"status\": batch.status,\n",
    "            \"completed_at\": batch.completed_at,\n",
    "            \"failed_at\": batch.failed_at,\n",
    "            \"request_counts\": batch.request_counts.__dict__ if batch.request_counts else None\n",
    "        }\n",
    "\n",
    "    def download_batch_results(self, batch_id: str, output_filename: str = \"batch_results.jsonl\") -> str:\n",
    "        \"\"\"\n",
    "        배치 작업 결과 다운로드\n",
    "\n",
    "        Args:\n",
    "            batch_id: 배치 작업 ID\n",
    "            output_filename: 결과 저장 파일명\n",
    "\n",
    "        Returns:\n",
    "            다운로드된 파일 경로\n",
    "        \"\"\"\n",
    "        batch = self.client.batches.retrieve(batch_id)\n",
    "\n",
    "        if batch.status != \"completed\":\n",
    "            raise Exception(f\"Batch not completed. Status: {batch.status}\")\n",
    "\n",
    "        # 결과 파일 다운로드\n",
    "        result_file_id = batch.output_file_id\n",
    "        result = self.client.files.content(result_file_id)\n",
    "\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(result.content)\n",
    "\n",
    "        logger.info(f\"Downloaded batch results to: {output_filename}\")\n",
    "        return output_filename\n",
    "\n",
    "    def parse_batch_results(self, results_file_path: str) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        배치 결과 파일 파싱\n",
    "\n",
    "        Args:\n",
    "            results_file_path: 결과 파일 경로\n",
    "\n",
    "        Returns:\n",
    "            파싱된 결과 딕셔너리\n",
    "        \"\"\"\n",
    "        parsed_results = {}\n",
    "\n",
    "        with open(results_file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                result = json.loads(line.strip())\n",
    "                custom_id = result['custom_id']\n",
    "                corp_code = custom_id.replace('analysis_', '')\n",
    "\n",
    "                try:\n",
    "                    # GPT 응답에서 JSON 추출\n",
    "                    response_content = result['response']['body']['choices'][0]['message']['content']\n",
    "                    analysis_data = json.loads(response_content)\n",
    "\n",
    "                    parsed_results[corp_code] = {\n",
    "                        'positive_factors': analysis_data.get('positive_factors', []),\n",
    "                        'negative_factors': analysis_data.get('negative_factors', [])\n",
    "                    }\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error parsing result for {corp_code}: {e}\")\n",
    "                    parsed_results[corp_code] = {\n",
    "                        'positive_factors': [],\n",
    "                        'negative_factors': []\n",
    "                    }\n",
    "\n",
    "        return parsed_results\n",
    "\n",
    "    def integrate_with_financial_data(self, csv_path: str, analysis_results: Dict[str, Dict],\n",
    "                                    output_path: str = \"integrated_financial_data.csv\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        재무 데이터와 정성적 분석 결과 통합\n",
    "\n",
    "        Args:\n",
    "            csv_path: 원본 재무 데이터 CSV 경로\n",
    "            analysis_results: 정성적 분석 결과\n",
    "            output_path: 통합 결과 저장 경로\n",
    "\n",
    "        Returns:\n",
    "            통합된 DataFrame\n",
    "        \"\"\"\n",
    "        # 원본 재무 데이터 로드\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logger.info(f\"Loaded financial data: {len(df)} records\")\n",
    "\n",
    "        # 정성적 요인 컬럼 추가\n",
    "        df['positive_factors'] = ''\n",
    "        df['negative_factors'] = ''\n",
    "\n",
    "        # 분석 결과와 매칭하여 데이터 추가\n",
    "        matched_count = 0\n",
    "        for idx, row in df.iterrows():\n",
    "            corp_code = str(row['corp_code'])\n",
    "\n",
    "            if corp_code in analysis_results:\n",
    "                positive_factors = analysis_results[corp_code]['positive_factors']\n",
    "                negative_factors = analysis_results[corp_code]['negative_factors']\n",
    "\n",
    "                # 리스트를 문자열로 변환 (JSON 배열 형태로)\n",
    "                df.at[idx, 'positive_factors'] = json.dumps(positive_factors, ensure_ascii=False)\n",
    "                df.at[idx, 'negative_factors'] = json.dumps(negative_factors, ensure_ascii=False)\n",
    "\n",
    "                matched_count += 1\n",
    "\n",
    "        logger.info(f\"Matched {matched_count}/{len(df)} records with analysis results\")\n",
    "\n",
    "        # 결과 저장\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        logger.info(f\"Integrated data saved to: {output_path}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    메인 실행 함수\n",
    "    \"\"\"\n",
    "    # OpenAI API 키 설정 (환경변수에서 가져오거나 직접 입력)\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        api_key = input(\"OpenAI API 키를 입력하세요: \")\n",
    "\n",
    "    # 경로 설정\n",
    "    folder_path = \"D:/JetBrains/ai/add-data-real-company\"\n",
    "    csv_path = os.path.join(folder_path, \"dart_general_company_financial_fixed.csv\")\n",
    "\n",
    "    # 분석기 초기화\n",
    "    analyzer = QualitativeAnalyzer(api_key)\n",
    "\n",
    "    try:\n",
    "        # 1. 검색 결과 로드\n",
    "        logger.info(\"Loading search results...\")\n",
    "        search_results = analyzer.load_search_results(folder_path)\n",
    "\n",
    "        if not search_results:\n",
    "            logger.error(\"No search results found!\")\n",
    "            return\n",
    "\n",
    "        # 2. 배치 요청 준비\n",
    "        logger.info(\"Preparing batch requests...\")\n",
    "        batch_requests = analyzer.prepare_batch_requests(search_results, model=\"gpt-4o-mini\")\n",
    "\n",
    "        # 3. 배치 파일 생성\n",
    "        batch_file = analyzer.create_batch_file(batch_requests, \"qualitative_analysis_batch.jsonl\")\n",
    "\n",
    "        # 4. 배치 작업 제출\n",
    "        logger.info(\"Submitting batch to OpenAI...\")\n",
    "        batch_id = analyzer.submit_batch(batch_file)\n",
    "        print(f\"Batch ID: {batch_id}\")\n",
    "        print(\"배치 작업이 제출되었습니다. 완료까지 시간이 걸릴 수 있습니다.\")\n",
    "\n",
    "        # 5. 상태 확인 (완료될 때까지 대기)\n",
    "        logger.info(\"Waiting for batch completion...\")\n",
    "        while True:\n",
    "            status = analyzer.check_batch_status(batch_id)\n",
    "            print(f\"Status: {status['status']}\")\n",
    "\n",
    "            if status['status'] == 'completed':\n",
    "                logger.info(\"Batch completed successfully!\")\n",
    "                break\n",
    "            elif status['status'] in ['failed', 'cancelled']:\n",
    "                logger.error(f\"Batch failed with status: {status['status']}\")\n",
    "                return\n",
    "\n",
    "            time.sleep(60)  # 1분마다 상태 확인\n",
    "\n",
    "        # 6. 결과 다운로드\n",
    "        logger.info(\"Downloading batch results...\")\n",
    "        results_file = analyzer.download_batch_results(batch_id, \"qualitative_results.jsonl\")\n",
    "\n",
    "        # 7. 결과 파싱\n",
    "        logger.info(\"Parsing batch results...\")\n",
    "        analysis_results = analyzer.parse_batch_results(results_file)\n",
    "\n",
    "        # 8. 재무 데이터와 통합\n",
    "        logger.info(\"Integrating with financial data...\")\n",
    "        integrated_df = analyzer.integrate_with_financial_data(\n",
    "            csv_path,\n",
    "            analysis_results,\n",
    "            os.path.join(folder_path, \"integrated_financial_qualitative_data.csv\")\n",
    "        )\n",
    "\n",
    "        print(f\"완료! 통합된 데이터: {len(integrated_df)} 행\")\n",
    "        print(\"새로운 컬럼:\")\n",
    "        print(\"- positive_factors: 긍정적 요인들\")\n",
    "        print(\"- negative_factors: 부정적 요인들\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main process: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# 배치가 이미 실행 중인 경우 상태 확인 및 결과 처리 함수\n",
    "def process_existing_batch(batch_id: str, api_key: str, folder_path: str):\n",
    "    \"\"\"\n",
    "    기존 배치 작업의 결과를 처리하는 함수\n",
    "\n",
    "    Args:\n",
    "        batch_id: 기존 배치 작업 ID\n",
    "        api_key: OpenAI API 키\n",
    "        folder_path: 작업 폴더 경로\n",
    "    \"\"\"\n",
    "    analyzer = QualitativeAnalyzer(api_key)\n",
    "    csv_path = os.path.join(folder_path, \"dart_general_company_financial_fixed.csv\")\n",
    "\n",
    "    try:\n",
    "        # 상태 확인\n",
    "        status = analyzer.check_batch_status(batch_id)\n",
    "        print(f\"Batch Status: {status}\")\n",
    "\n",
    "        if status['status'] == 'completed':\n",
    "            # 결과 다운로드 및 처리\n",
    "            results_file = analyzer.download_batch_results(batch_id, \"qualitative_results.jsonl\")\n",
    "            analysis_results = analyzer.parse_batch_results(results_file)\n",
    "\n",
    "            # 재무 데이터와 통합\n",
    "            integrated_df = analyzer.integrate_with_financial_data(\n",
    "                csv_path,\n",
    "                analysis_results,\n",
    "                os.path.join(folder_path, \"integrated_financial_qualitative_data.csv\")\n",
    "            )\n",
    "\n",
    "            print(f\"완료! 통합된 데이터: {len(integrated_df)} 행\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing existing batch: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "c162f7e54e3460ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1de2c917bac114eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
